{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "484677ff-5727-48da-a4e4-22549a8e5884",
   "metadata": {},
   "source": [
    "# ANSWER 1\n",
    "## Linear Regression\t\n",
    "\n",
    "Linear regression is used to predict the continuous dependent variable using a given set of independent variables.\t\n",
    "\n",
    "In Linear regression, we predict the value of continuous variables.\n",
    "\n",
    "In linear regression, we find the best fit line, by which we can easily predict the output.\t\n",
    "\n",
    "Least square estimation method is used for estimation of accuracy.\n",
    "\n",
    "The output for Linear Regression must be a continuous value, such as price, age, etc.\t\n",
    "\n",
    "In Linear regression, it is required that relationship between dependent variable and independent variable must be linear.\n",
    "\n",
    "In linear regression, there may be collinearity between the independent variables.\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "Logistic Regression is used to predict the categorical dependent variable using a given set of independent variables.\n",
    "\n",
    "In logistic Regression, we predict the values of categorical variables.\n",
    "\n",
    "In Logistic Regression, we find the S-curve by which we can classify the samples.\n",
    "\n",
    "Maximum likelihood estimation method is used for estimation of accuracy.\n",
    "\n",
    "The output of Logistic Regression must be a Categorical value such as 0 or 1, Yes or No, etc.\n",
    "\n",
    "In Logistic regression, it is not required to have the linear relationship between the dependent and independent variable.\n",
    "\n",
    "In logistic regression, there should not be collinearity between the independent variable.\n",
    "\n",
    "\n",
    "# --> For example, a logistic regression could be used to predict whether a political candidate will win or lose an election or whether a high school student will be admitted or not to a particular college. These binary outcomes allow straightforward decisions between two alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a8b5b-ac22-4165-8f0b-3cf1f2e7966f",
   "metadata": {},
   "source": [
    "# ANSWER 2 \n",
    "Log Loss-The cost function used in Logistic Regression.\n",
    "\n",
    "\"Gradient Descent is an optimization algorithm which is used for optimizing the cost function\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a43b4-14fc-4933-a3b8-b4858624c33b",
   "metadata": {},
   "source": [
    "# ANSWER 3\n",
    "Regularization helps you avoid overfitting by adding a penalty term to the cost function of your model, which measures how well your model fits the data. The penalty term reduces the complexity of your model by shrinking or eliminating some of the coefficients of your input variables.\n",
    "\n",
    "Regularization is a technique that penalizes the coefficient. In an overfit model, the coefficients are generally inflated. Thus, Regularization adds penalties to the parameters and avoids them weigh heavily. The coefficients are added to the cost function of the linear equation.\n",
    "\n",
    "Regularization in machine learning is the process of regularizing the parameters that constrain, regularizes, or shrinks the coefficient estimates towards zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627790ee-8315-47fc-8d1b-2ad8cc1d1374",
   "metadata": {},
   "source": [
    "# ANSWER 4\n",
    "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate. False Positive Rate.\n",
    "\n",
    "ROC curves in logistic regression are used for determining the best cutoff value for predicting whether a new observation is a \"failure\" (0) or a \"success\" (1). \n",
    "\n",
    "ROC curves help us visualize how these choices affect classifier performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bb28a4-dda8-429e-8939-b109cb4952ac",
   "metadata": {},
   "source": [
    "# ANSWER 5 \n",
    "L1 regularization introduces sparsity in the dataset, and it can use to perform feature selection by eliminating the features that are not important.\n",
    "\n",
    "L1 regularization, also known as “Lasso”, adds a penalty on the sum of the absolute values of the model weights. This means that weights that do not contribute much to the model will be zeroed, which can lead to automatic feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67390d7b-6e7d-4638-b905-8f6e603cc9ce",
   "metadata": {},
   "source": [
    "# ANSWER 6\n",
    "7 Techniques to Handle Imbalanced Data. \n",
    "\n",
    "1 Use the right evaluation metrics. \n",
    "\n",
    "2 Resample the training set.\n",
    "\n",
    "3 Use K-fold Cross-Validation in the Right Way. \n",
    "\n",
    "4 Ensemble Different Resampled Datasets. \n",
    "\n",
    "5 Resample with Different Ratios. \n",
    "\n",
    "6 Cluster the abundant class. \n",
    "\n",
    "7 Design Your Models.\n",
    "\n",
    "There are many techniques available to handle class imbalance. One of the popular techniques is up-sampling (e.g. SMOTE) in which more similar data points are added to minority class to make class distribution equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21995d-1b5b-46d2-b311-abcfb41fcab1",
   "metadata": {},
   "source": [
    "# ANSWER 7\n",
    "## some common issues and challenges that may arise when implementing logistic regression\n",
    "Logistic regression fails to predict a continuous outcome.\n",
    "\n",
    "Logistic regression assumes linearity between the predicted (dependent) variable and the predictor (independent) variables.\n",
    "\n",
    "Logistic regression may not be accurate if the sample size is too small.\n",
    "\n",
    "If the number of observations is lesser than the number of features, Logistic Regression should not be used, otherwise, it may lead to overfitting. It makes no assumptions about distributions of classes in feature space. It constructs linear boundaries.\n",
    "\n",
    "## if there is multicollinearity among the independent variables\n",
    "\n",
    "Multicollinearity causes the following two basic types of problems:\n",
    "\n",
    "The coefficient estimates can swing wildly based on which other independent variables are in the model. The coefficients become very sensitive to small changes in the model.\n",
    "\n",
    "Multicollinearity reduces the precision of the estimated coefficients, which weakens the statistical power of your regression model. You might not be able to trust the p-values to identify independent variables that are statistically significant.\n",
    "\n",
    "--> SOLUTION IS \n",
    "\n",
    "-- > Remove some of the highly correlated independent variables.\n",
    "\n",
    "--> Linearly combine the independent variables, such as adding them together.\n",
    "\n",
    "--> Partial least squares regression uses principal component analysis to create a set of uncorrelated components to include in the model.\n",
    "\n",
    "--> LASSO and Ridge regression are advanced forms of regression analysis that can handle multicollinearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5cf29-03d4-4441-80f0-ba3ef8e31008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9d2ac-7bc2-4978-ad82-227fdf410967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8cee95-804e-4b2a-8c7f-900f2d4076d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa43f94-aa24-4c11-85f3-d5bd569e4200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
